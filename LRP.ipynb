{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"/Users/Work/Developer/interpretDL/interprettensor\")\n",
    "root_logdir = \"./tf_logs\"\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_analysis(model, analyzer, data, labels):\n",
    "    analysis = analyzer.analyze(data)\n",
    "    prediction = model.predict(data)\n",
    "    \n",
    "    df_anal = pd.DataFrame(analysis)\n",
    "    \n",
    "    return df_anal\n",
    "\n",
    "def get_relevant_cols(df, thresh = 1e-2):\n",
    "\n",
    "    all_above_thresh = (df < thresh).all(0) #Check if all values in columns satisfy the criteria\n",
    "    max_above_thresh = (df.max() < thresh)\n",
    "    quantile_above_thresh = (df.quantile(0.8) < thresh)\n",
    "\n",
    "    criteria = quantile_above_thresh\n",
    "    irrelevant_cols = df.columns[criteria] \n",
    "    irrelevant_cols\n",
    "    \n",
    "    relevant_features_only = all_lrp.drop(columns = irrelevant_cols)\n",
    "    \n",
    "    return relevant_features_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"AD_CN_TH.csv\"\n",
    "raw_data = pd.read_csv(filename, index_col= 0)\n",
    "features = raw_data.drop([\"labels\"],axis=1,)\n",
    "labels = raw_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([12, 62, 65, 108, 118, 126, 133], dtype='int64')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = pd.read_csv(\"test_indices.csv\", dtype=int, index_col=0)[\"0\"]\n",
    "test_samples = features.iloc[test_idx].index\n",
    "train_samples = features.drop(test_samples, axis=\"index\")\n",
    "test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: [array(['AD', 'CN'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# Selecting a DNN\n",
    "model = load_model(\"best_dnn.h5\")\n",
    "\n",
    "hot_encoder = OneHotEncoder(categories=\"auto\", sparse=False)\n",
    "hot_encoder.fit(labels.values.reshape(-1,1))\n",
    "sample_labels = hot_encoder.transform([[label] for label in labels])\n",
    "print(\"Categories:\", hot_encoder.categories_)\n",
    "\n",
    "ZScaler = StandardScaler()\n",
    "ZScaler.fit(train_samples)\n",
    "samples = ZScaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SANITY CHECK\n",
      "76/76 [==============================] - 0s 3ms/step\n",
      "Scores on test set: loss=0.246 accuracy=1.0000\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(samples)\n",
    "preds = np.array([np.argmax(x) for x in predictions])\n",
    "true_labels = np.array([np.argmax(x) for x in sample_labels])\n",
    "\n",
    "correct = preds == true_labels\n",
    "AD_Sample = true_labels == 0\n",
    "\n",
    "correct_preds = preds[correct]\n",
    "correct_preds.shape\n",
    "\n",
    "print(\"SANITY CHECK\")\n",
    "loss_and_metrics = model.evaluate(samples[correct], sample_labels[correct])\n",
    "print(\"Scores on test set: loss={:0.3f} accuracy={:.4f}\".format(*loss_and_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "\n",
    "\n",
    "# Stripping the softmax activation from the model\n",
    "model_wo_sm = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "# Creating an analyzer\n",
    "lrp_E = innvestigate.analyzer.relevance_based.relevance_analyzer.LRPEpsilon(model=model_wo_sm)\n",
    "\n",
    "lrp = innvestigate.analyzer.relevance_based.relevance_analyzer.LRPAlpha2Beta1(model=model_wo_sm)\n",
    "\n",
    "# Getting all the samples that can be correctly predicted\n",
    "test_idx = correct\n",
    "all_samples = samples[test_idx] \n",
    "all_labels = sample_labels[test_idx]\n",
    "\n",
    "# perform_analysis(nn,gradient_analyzer,flowers,types)\n",
    "all_lrp = perform_analysis(model,lrp, all_samples, all_labels)\n",
    "\n",
    "all_lrp_E = perform_analysis(model,lrp_E, all_samples, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.Axes3DSubplot at 0x14844a208>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp_results = all_lrp\n",
    "# lrp_E_results = all_lrp_E\n",
    "population = lrp_results.mean()\n",
    "population.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G_oc-temp_med-Parahip_TH_rh', 'S_precentral-sup-part_TH_lh',\n",
       "       'G_oc-temp_med-Parahip_TH_lh', 'G_front_inf-Orbital_TH_lh',\n",
       "       'G_cingul-Post-dorsal_TH_rh', 'G_orbital_TH_rh'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_features = population.sort_values(ascending=False)\n",
    "best_features = sorted_features[:6]\n",
    "\n",
    "features.columns[best_features.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042596</td>\n",
       "      <td>-0.003920</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>0.034732</td>\n",
       "      <td>0.019030</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>-0.000682</td>\n",
       "      <td>-0.017008</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.258553</td>\n",
       "      <td>0.223624</td>\n",
       "      <td>0.461686</td>\n",
       "      <td>0.171120</td>\n",
       "      <td>0.092938</td>\n",
       "      <td>0.031058</td>\n",
       "      <td>0.024395</td>\n",
       "      <td>0.024588</td>\n",
       "      <td>0.027262</td>\n",
       "      <td>0.069183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045212</td>\n",
       "      <td>0.028789</td>\n",
       "      <td>0.063435</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>0.082244</td>\n",
       "      <td>0.045732</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.024586</td>\n",
       "      <td>0.135524</td>\n",
       "      <td>0.009963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.618569</td>\n",
       "      <td>-1.807765</td>\n",
       "      <td>-3.446275</td>\n",
       "      <td>-0.354645</td>\n",
       "      <td>-0.346158</td>\n",
       "      <td>-0.134870</td>\n",
       "      <td>-0.072854</td>\n",
       "      <td>-0.200798</td>\n",
       "      <td>-0.036922</td>\n",
       "      <td>-0.436161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103110</td>\n",
       "      <td>-0.028655</td>\n",
       "      <td>-0.037577</td>\n",
       "      <td>-0.016503</td>\n",
       "      <td>-0.135802</td>\n",
       "      <td>-0.079952</td>\n",
       "      <td>-0.028642</td>\n",
       "      <td>-0.197539</td>\n",
       "      <td>-1.137114</td>\n",
       "      <td>-0.064132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.010943</td>\n",
       "      <td>-0.002689</td>\n",
       "      <td>-0.025059</td>\n",
       "      <td>-0.007361</td>\n",
       "      <td>-0.005988</td>\n",
       "      <td>-0.001873</td>\n",
       "      <td>-0.003449</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.002898</td>\n",
       "      <td>-0.002143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006790</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>-0.005512</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>-0.001448</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000899</td>\n",
       "      <td>-0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>0.068085</td>\n",
       "      <td>0.036760</td>\n",
       "      <td>0.042037</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.011595</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.007487</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.828964</td>\n",
       "      <td>0.416703</td>\n",
       "      <td>1.396092</td>\n",
       "      <td>1.381291</td>\n",
       "      <td>0.347212</td>\n",
       "      <td>0.153877</td>\n",
       "      <td>0.156249</td>\n",
       "      <td>0.036516</td>\n",
       "      <td>0.211771</td>\n",
       "      <td>0.322382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251897</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.406834</td>\n",
       "      <td>0.092465</td>\n",
       "      <td>0.624229</td>\n",
       "      <td>0.336468</td>\n",
       "      <td>0.202937</td>\n",
       "      <td>0.023239</td>\n",
       "      <td>0.097216</td>\n",
       "      <td>0.013877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5    \\\n",
       "count  76.000000  76.000000  76.000000  76.000000  76.000000  76.000000   \n",
       "mean    0.042596  -0.003920  -0.003798   0.034732   0.019030  -0.000935   \n",
       "std     0.258553   0.223624   0.461686   0.171120   0.092938   0.031058   \n",
       "min    -0.618569  -1.807765  -3.446275  -0.354645  -0.346158  -0.134870   \n",
       "25%    -0.010943  -0.002689  -0.025059  -0.007361  -0.005988  -0.001873   \n",
       "50%     0.002077   0.015170   0.003013   0.003445   0.009111   0.000328   \n",
       "75%     0.015865   0.041253   0.068085   0.036760   0.042037   0.003882   \n",
       "max     1.828964   0.416703   1.396092   1.381291   0.347212   0.153877   \n",
       "\n",
       "             6          7          8          9    ...        138        139  \\\n",
       "count  76.000000  76.000000  76.000000  76.000000  ...  76.000000  76.000000   \n",
       "mean    0.005752   0.000653   0.004047   0.002100  ...   0.002124   0.005619   \n",
       "std     0.024395   0.024588   0.027262   0.069183  ...   0.045212   0.028789   \n",
       "min    -0.072854  -0.200798  -0.036922  -0.436161  ...  -0.103110  -0.028655   \n",
       "25%    -0.003449  -0.000500  -0.002898  -0.002143  ...  -0.006790  -0.000364   \n",
       "50%     0.001001   0.000816   0.000916   0.004374  ...   0.000347   0.000552   \n",
       "75%     0.011595   0.004271   0.005550   0.012642  ...   0.004167   0.003234   \n",
       "max     0.156249   0.036516   0.211771   0.322382  ...   0.251897   0.209000   \n",
       "\n",
       "             140        141        142        143        144        145  \\\n",
       "count  76.000000  76.000000  76.000000  76.000000  76.000000  76.000000   \n",
       "mean    0.010609   0.002386   0.011664   0.010957   0.004685  -0.000682   \n",
       "std     0.063435   0.013141   0.082244   0.045732   0.025372   0.024586   \n",
       "min    -0.037577  -0.016503  -0.135802  -0.079952  -0.028642  -0.197539   \n",
       "25%    -0.005512  -0.001171  -0.001448  -0.000221  -0.001390  -0.000161   \n",
       "50%    -0.000096  -0.000082   0.000905   0.001832   0.000597   0.001910   \n",
       "75%     0.006340   0.003704   0.007487   0.009538   0.003157   0.004971   \n",
       "max     0.406834   0.092465   0.624229   0.336468   0.202937   0.023239   \n",
       "\n",
       "             146        147  \n",
       "count  76.000000  76.000000  \n",
       "mean   -0.017008   0.000210  \n",
       "std     0.135524   0.009963  \n",
       "min    -1.137114  -0.064132  \n",
       "25%    -0.000899  -0.000863  \n",
       "50%     0.000071   0.000591  \n",
       "75%     0.001288   0.004082  \n",
       "max     0.097216   0.013877  \n",
       "\n",
       "[8 rows x 148 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fig = plt.figure()\n",
    "# population = all_lrp.mean()\n",
    "# sorted_features = population.sort_values(ascending=False)\n",
    "# sorted_features.plot(kind=\"bar\", figsize=[12,10])\n",
    "# plt.xticks(rotation=65, fontsize=\"small\")\n",
    "desc = lrp_results.describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_cols(df, thresh = 1e-2):\n",
    "\n",
    "    all_above_thresh = (df < thresh).all(0) #Check if all values in columns satisfy the criteria\n",
    "    max_above_thresh = (df.max() < thresh)\n",
    "    quantile_above_thresh = (df.quantile(0.8) < thresh)\n",
    "\n",
    "    criteria = quantile_above_thresh\n",
    "    irrelevant_cols = df.columns[criteria] \n",
    "    irrelevant_cols\n",
    "    \n",
    "    relevant_features_only = all_lrp.drop(columns = irrelevant_cols)\n",
    "    \n",
    "    return relevant_features_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>121</th>\n",
       "      <th>123</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>132</th>\n",
       "      <th>134</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>143</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042596</td>\n",
       "      <td>-0.003920</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>0.034732</td>\n",
       "      <td>0.019030</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>0.049915</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017248</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.046566</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>-0.103683</td>\n",
       "      <td>-0.009122</td>\n",
       "      <td>-0.022484</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.029794</td>\n",
       "      <td>0.010957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.258553</td>\n",
       "      <td>0.223624</td>\n",
       "      <td>0.461686</td>\n",
       "      <td>0.171120</td>\n",
       "      <td>0.092938</td>\n",
       "      <td>0.024395</td>\n",
       "      <td>0.069183</td>\n",
       "      <td>0.094439</td>\n",
       "      <td>0.598275</td>\n",
       "      <td>0.545583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157852</td>\n",
       "      <td>0.029446</td>\n",
       "      <td>0.527406</td>\n",
       "      <td>0.145763</td>\n",
       "      <td>1.015396</td>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.304771</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.117416</td>\n",
       "      <td>0.045732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.618569</td>\n",
       "      <td>-1.807765</td>\n",
       "      <td>-3.446275</td>\n",
       "      <td>-0.354645</td>\n",
       "      <td>-0.346158</td>\n",
       "      <td>-0.072854</td>\n",
       "      <td>-0.436161</td>\n",
       "      <td>-0.595094</td>\n",
       "      <td>-1.144035</td>\n",
       "      <td>-3.365649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545281</td>\n",
       "      <td>-0.175718</td>\n",
       "      <td>-1.878063</td>\n",
       "      <td>-1.138978</td>\n",
       "      <td>-7.565024</td>\n",
       "      <td>-0.396798</td>\n",
       "      <td>-2.278876</td>\n",
       "      <td>-0.347809</td>\n",
       "      <td>-0.190511</td>\n",
       "      <td>-0.079952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.010943</td>\n",
       "      <td>-0.002689</td>\n",
       "      <td>-0.025059</td>\n",
       "      <td>-0.007361</td>\n",
       "      <td>-0.005988</td>\n",
       "      <td>-0.003449</td>\n",
       "      <td>-0.002143</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.070138</td>\n",
       "      <td>-0.020153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.020477</td>\n",
       "      <td>-0.006386</td>\n",
       "      <td>-0.027307</td>\n",
       "      <td>-0.009577</td>\n",
       "      <td>-0.031321</td>\n",
       "      <td>-0.022712</td>\n",
       "      <td>-0.001606</td>\n",
       "      <td>-0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.001832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>0.068085</td>\n",
       "      <td>0.036760</td>\n",
       "      <td>0.042037</td>\n",
       "      <td>0.011595</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.027627</td>\n",
       "      <td>0.086324</td>\n",
       "      <td>0.093517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>0.045913</td>\n",
       "      <td>0.038671</td>\n",
       "      <td>0.044070</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>0.060845</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>0.033802</td>\n",
       "      <td>0.009538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.828964</td>\n",
       "      <td>0.416703</td>\n",
       "      <td>1.396092</td>\n",
       "      <td>1.381291</td>\n",
       "      <td>0.347212</td>\n",
       "      <td>0.156249</td>\n",
       "      <td>0.322382</td>\n",
       "      <td>0.304244</td>\n",
       "      <td>4.814804</td>\n",
       "      <td>2.682676</td>\n",
       "      <td>...</td>\n",
       "      <td>1.242268</td>\n",
       "      <td>0.118880</td>\n",
       "      <td>2.919530</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>2.914621</td>\n",
       "      <td>0.067084</td>\n",
       "      <td>0.815949</td>\n",
       "      <td>1.008004</td>\n",
       "      <td>0.912922</td>\n",
       "      <td>0.336468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          6    \\\n",
       "count  76.000000  76.000000  76.000000  76.000000  76.000000  76.000000   \n",
       "mean    0.042596  -0.003920  -0.003798   0.034732   0.019030   0.005752   \n",
       "std     0.258553   0.223624   0.461686   0.171120   0.092938   0.024395   \n",
       "min    -0.618569  -1.807765  -3.446275  -0.354645  -0.346158  -0.072854   \n",
       "25%    -0.010943  -0.002689  -0.025059  -0.007361  -0.005988  -0.003449   \n",
       "50%     0.002077   0.015170   0.003013   0.003445   0.009111   0.001001   \n",
       "75%     0.015865   0.041253   0.068085   0.036760   0.042037   0.011595   \n",
       "max     1.828964   0.416703   1.396092   1.381291   0.347212   0.156249   \n",
       "\n",
       "             9          10         12         13   ...        121        123  \\\n",
       "count  76.000000  76.000000  76.000000  76.000000  ...  76.000000  76.000000   \n",
       "mean    0.002100  -0.001536   0.049915   0.013953  ...   0.017248   0.007985   \n",
       "std     0.069183   0.094439   0.598275   0.545583  ...   0.157852   0.029446   \n",
       "min    -0.436161  -0.595094  -1.144035  -3.365649  ...  -0.545281  -0.175718   \n",
       "25%    -0.002143  -0.017833  -0.070138  -0.020153  ...   0.000292  -0.000260   \n",
       "50%     0.004374  -0.000118   0.011632   0.013760  ...   0.005905   0.003911   \n",
       "75%     0.012642   0.027627   0.086324   0.093517  ...   0.015060   0.017853   \n",
       "max     0.322382   0.304244   4.814804   2.682676  ...   1.242268   0.118880   \n",
       "\n",
       "             125        126        127        132        134        136  \\\n",
       "count  76.000000  76.000000  76.000000  76.000000  76.000000  76.000000   \n",
       "mean    0.046566   0.008115  -0.103683  -0.009122  -0.022484   0.012433   \n",
       "std     0.527406   0.145763   1.015396   0.064157   0.304771   0.161290   \n",
       "min    -1.878063  -1.138978  -7.565024  -0.396798  -2.278876  -0.347809   \n",
       "25%    -0.020477  -0.006386  -0.027307  -0.009577  -0.031321  -0.022712   \n",
       "50%     0.005562   0.009208   0.005444   0.004811   0.001989   0.002938   \n",
       "75%     0.045913   0.038671   0.044070   0.015188   0.060845   0.015839   \n",
       "max     2.919530   0.271285   2.914621   0.067084   0.815949   1.008004   \n",
       "\n",
       "             137        143  \n",
       "count  76.000000  76.000000  \n",
       "mean    0.029794   0.010957  \n",
       "std     0.117416   0.045732  \n",
       "min    -0.190511  -0.079952  \n",
       "25%    -0.001606  -0.000221  \n",
       "50%     0.006730   0.001832  \n",
       "75%     0.033802   0.009538  \n",
       "max     0.912922   0.336468  \n",
       "\n",
       "[8 rows x 71 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_features_only = get_relevant_cols(all_lrp)\n",
    "relevant_features_only.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=42,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pos_only = all_lrp.copy()\n",
    "pos_only[pos_only < 0] = 0\n",
    "pca.fit(pos_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  [0.41100113 0.27924447]\n"
     ]
    }
   ],
   "source": [
    "print(\"Variance: \", pca.explained_variance_ratio_)\n",
    "# pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: [array(['AD', 'CN'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "X = pca.transform(pos_only)\n",
    "df = pd.DataFrame(X, columns=[\"PC1\",\"PC2\"])\n",
    "_labels = np.array([np.argmax(x) for x in all_labels])\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "df.plot.scatter(x=\"PC1\", y=\"PC2\", s= 30, c=_labels, colormap='winter',figsize=(10,8))\n",
    "# plt.legend([\"AD\", \"CN\"])\n",
    "print(\"Categories:\", hot_encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot PCA for 3 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_2d(X,labels, name=\"1\"):\n",
    "#     plt.close()\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    plt.scatter(x=X[:,0], y=X[:,1], s= 30, c=_labels)\n",
    "    plt.colorbar()\n",
    "\n",
    "def plot_3d(X, labels):\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(X[:,0], X[:,1], X[:,2], c=labels, s=40)\n",
    "    ax.set(xlabel=\"x\", ylabel=\"y\", zlabel=\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  [0.55622541 0.28497895 0.05635775]\n"
     ]
    }
   ],
   "source": [
    "pca3 = PCA(n_components=3)\n",
    "pca3.fit(pos_only)\n",
    "print(\"Variance: \", pca3.explained_variance_ratio_)\n",
    "\n",
    "pc_3d = pca3.transform(pos_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'PC3'), Text(0.5, 0, 'PC2'), Text(0.5, 0, 'PC1')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pc_3d[:,0], pc_3d[:,1], pc_3d[:,2], c=_labels, s=40)\n",
    "ax.set(xlabel=\"PC1\", ylabel=\"PC2\", zlabel=\"PC3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# pca_reduced = PCA(n_components=50)\n",
    "tSNE = TSNE(n_components=2, init=\"pca\", random_state=42)\n",
    "tSNE_relevance = tSNE.fit_transform(pos_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 2)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tSNE_relevance\n",
    "plot_2d(X, labels)\n",
    "# plot_3d(X,_labels)\n",
    "\n",
    "    \n",
    "tSNE_relevance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "# %matplotlib widget\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures not being reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db68da8aa83c49fd8c7242b424b2b848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_only = get_relevant_cols(all_lrp)\n",
    "# pos_only = lrp_results.copy()\n",
    "plt.close()\n",
    "# pos_only[pos_only < 0] = 0\n",
    "reducer = umap.UMAP(random_state=42,\n",
    "                    n_components = 2,\n",
    "                    n_neighbors=3,\n",
    "                    min_dist=0)\n",
    "embedding = reducer.fit_transform(pos_only)\n",
    "plot_2d(embedding, _labels, name=\"Alpha\")\n",
    "\n",
    "# fig = plt.figure(figsize=(10,8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(embedding[:,0], embedding[:,1], embedding[:,2], c=_labels, s=40)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e397e0a1ba094a98999406ab49c08074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940fddb3728743b785575aa781cfe55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_only = get_relevant_cols(all_lrp_E)\n",
    "# pos_only = all_lrp_E.copy()\n",
    "pos_only[pos_only < 0] = 0\n",
    "\n",
    "reducer = umap.UMAP(random_state=42,\n",
    "                    n_components = 3,\n",
    "                    n_neighbors=3,\n",
    "                    min_dist=0)\n",
    "embedding = reducer.fit_transform(pos_only)\n",
    "\n",
    "plot_3d(embedding, _labels)\n",
    "\n",
    "plot_2d(embedding, _labels, name=\"Epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaflow",
   "language": "python",
   "name": "condaflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
