{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Magic line to force reload all modules when this cell is run multiple times\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ClusterPipeline import ClusterPipeline\n",
    "# from common_imports import *\n",
    "from helper import simulate_blobs\n",
    "from helper import plot_confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_index(features, labels, test_size=0.1):\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    \n",
    "    features = np.array(features)\n",
    "    # The train set will have equal amounts of each target class\n",
    "    # Performing single split\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "    return [[train_index, test_index] for train_index,test_index in split.split(features, labels)]\n",
    "\n",
    "def split_valid(features, training_labels, valid_size=0.5):\n",
    "    train_index, validation_index = get_split_index(features, training_labels, test_size=valid_size)[0]\n",
    "    \n",
    "    X_valid, y_valid = features.iloc[validation_index], training_labels.iloc[validation_index]\n",
    "    X_train, y_train = features.iloc[train_index], training_labels.iloc[train_index]\n",
    "     \n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "    initial_lr = 0.1\n",
    "    decay_steps = 50\n",
    "    decay_rate = 0.1\n",
    "    \n",
    "    decayed_lr =  initial_lr * np.power(decay_rate, (epoch/decay_steps))\n",
    "#     print(\"New Learning Rate:\", decayed_lr)\n",
    "    return decayed_lr\n",
    "\n",
    "def build_dnn(num_features, num_nodes = 16, depth = 2, num_labels=2, activation = \"elu\"):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    import keras\n",
    "    from keras import optimizers\n",
    "    from keras import regularizers\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    reg_scale = 0.001 # For L1 Reg\n",
    "    my_reg = regularizers.l1_l2(reg_scale) # Can change this if needed\n",
    "    \n",
    "    dnn = keras.models.Sequential()\n",
    "\n",
    "    Dense = keras.layers.Dense\n",
    "\n",
    "    # Using He initialization\n",
    "    he_init = keras.initializers.he_normal()\n",
    "    \n",
    "\n",
    "    dnn.add(Dense(units = 100, activation=\"elu\", input_dim=num_features,\n",
    "                  kernel_initializer=he_init, kernel_regularizer = my_reg))\n",
    "    dnn.add(keras.layers.Dropout(0.5))\n",
    "    dnn.add(Dense(units = 50, activation=\"elu\",\n",
    "                  kernel_initializer=he_init, kernel_regularizer = my_reg))\n",
    "    dnn.add(keras.layers.Dropout(0.5))\n",
    "    dnn.add(Dense(units=25, activation='elu',\n",
    "                  kernel_initializer=he_init, kernel_regularizer = my_reg))\n",
    "    dnn.add(keras.layers.Dropout(0.5))\n",
    "    \n",
    "    dnn.add(Dense(units=num_labels, activation=\"softmax\",\n",
    "                  kernel_initializer=he_init, kernel_regularizer = my_reg)) # 5 labels -> logits for now\n",
    "    \n",
    "#     nadam = keras.optimizers.Nadam()\n",
    "    NSGD = keras.optimizers.SGD(lr=0.01,momentum=0.9,nesterov=True)\n",
    "    \n",
    "    dnn.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=NSGD,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76 entries, 2 to 142\n",
      "Columns: 149 entries, G_and_S_frontomargin_TH_lh to label\n",
      "dtypes: float64(148), object(1)\n",
      "memory usage: 89.1+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"data/ADNI_CN_AD.csv\", index_col=0)\n",
    "original_data = raw_data.drop(columns=[\"label\"])\n",
    "raw_labels = raw_data[\"label\"]\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['AD', 'CN'], dtype=object)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder(dtype=int)\n",
    "training_labels = np.ravel(oe.fit_transform(raw_labels.values.reshape(-1,1)))\n",
    "training_labels = pd.Series(training_labels)\n",
    "oe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CN    50\n",
       "AD    26\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               14900     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 21,277\n",
      "Trainable params: 21,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# pd.DataFrame(training_labels)\n",
    "nn = build_dnn(num_features=original_data.shape[1])\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UMAP(a=None, angular_rp_forest=False, b=None, init='spectral',\n",
       "     learning_rate=1.0, local_connectivity=1.0, metric='euclidean',\n",
       "     metric_kwds=None, min_dist=0.1, n_components=2, n_epochs=None,\n",
       "     n_neighbors=15, negative_sample_rate=5, random_state=42,\n",
       "     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n",
       "     target_metric='categorical', target_metric_kwds=None,\n",
       "     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n",
       "     transform_seed=42, verbose=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap.UMAP(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP(random_state=42,\n",
    "                    n_components = 10,\n",
    "                    n_neighbors=3,\n",
    "                    min_dist=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Serial Crossvalidation\n",
      "Running worker: 0\n",
      "Prediction Accuracy\n",
      "8/8 [==============================] - 0s 81us/step\n",
      "Scores on data set: loss=0.300 accuracy=0.8750\n",
      "Fold Correct: 7\n",
      "Finished training Fold: 0 -> Loss:0.300, Acc:0.8750\n",
      "Running worker: 1\n",
      "Prediction Accuracy\n",
      "8/8 [==============================] - 0s 83us/step\n",
      "Scores on data set: loss=1.086 accuracy=0.7500\n",
      "Fold Correct: 6\n",
      "Finished training Fold: 1 -> Loss:1.086, Acc:0.7500\n",
      "Running worker: 2\n",
      "Prediction Accuracy\n",
      "8/8 [==============================] - 0s 87us/step\n",
      "Scores on data set: loss=0.964 accuracy=0.7500\n",
      "Fold Correct: 6\n",
      "Finished training Fold: 2 -> Loss:0.964, Acc:0.7500\n",
      "Running worker: 3\n",
      "Prediction Accuracy\n",
      "7/7 [==============================] - 0s 107us/step\n",
      "Scores on data set: loss=0.493 accuracy=0.8571\n",
      "Fold Correct: 6\n",
      "Finished training Fold: 3 -> Loss:0.493, Acc:0.8571\n",
      "Running worker: 4\n",
      "Prediction Accuracy\n",
      "7/7 [==============================] - 0s 128us/step\n",
      "Scores on data set: loss=0.996 accuracy=0.8571\n",
      "Fold Correct: 6\n",
      "Finished training Fold: 4 -> Loss:0.996, Acc:0.8571\n",
      "Running worker: 5\n",
      "Prediction Accuracy\n",
      "6/6 [==============================] - 0s 104us/step\n",
      "Scores on data set: loss=0.442 accuracy=0.8333\n",
      "Fold Correct: 5\n",
      "Finished training Fold: 5 -> Loss:0.442, Acc:0.8333\n",
      "Running worker: 6\n",
      "Prediction Accuracy\n",
      "6/6 [==============================] - 0s 86us/step\n",
      "Scores on data set: loss=0.176 accuracy=1.0000\n",
      "Fold Correct: 6\n",
      "Finished training Fold: 6 -> Loss:0.176, Acc:1.0000\n",
      "Running worker: 7\n",
      "Prediction Accuracy\n",
      "6/6 [==============================] - 0s 151us/step\n",
      "Scores on data set: loss=1.026 accuracy=0.6667\n",
      "Fold Correct: 4\n",
      "Finished training Fold: 7 -> Loss:1.026, Acc:0.6667\n",
      "Running worker: 8\n",
      "Prediction Accuracy\n",
      "6/6 [==============================] - 0s 98us/step\n",
      "Scores on data set: loss=0.518 accuracy=0.6667\n",
      "Fold Correct: 4\n",
      "Finished training Fold: 8 -> Loss:0.518, Acc:0.6667\n",
      "Running worker: 9\n",
      "Prediction Accuracy\n",
      "6/6 [==============================] - 0s 112us/step\n",
      "Scores on data set: loss=0.599 accuracy=0.6667\n",
      "Fold Correct: 4\n",
      "Finished training Fold: 9 -> Loss:0.599, Acc:0.6667\n",
      "Runtime: 22.002s\n",
      "Correct: 54\n",
      "Test Size: 68\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Separating a hold out set that will be used for validation later\n",
    "    X_train, y_train, X_valid, y_valid = split_valid(original_data, training_labels, valid_size=0.1)    \n",
    "\n",
    "    pipeline = ClusterPipeline(nn, [X_train, y_train], [X_valid,y_valid], target_class=0, reducer=reducer)\n",
    "    \n",
    "    pipeline.train_model(batch_size=10,epochs=150, cross_validation=True, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[15  8]\n",
      " [ 6 39]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a5087b278>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [True,True,False].count(True)\n",
    "# np.array([True,True,False, True, False]).sum()\n",
    "plot_confusion_matrix(y_train.values[pipeline.testing_idxs], pipeline.predictions, oe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(pipeline.lrp_results)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %matplotlib notebook\n",
    "# import umap\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# reducer = umap.UMAP(random_state=42,\n",
    "#                     n_components = 3,\n",
    "#                     n_neighbors=3,\n",
    "#                     min_dist=0)\n",
    "# embedding = reducer.fit_transform(pipeline.lrp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, DNNs = pipeline.get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Size:\n",
      "Clusters                  4\n",
      "Noise                     3\n",
      "Silhouette                3\n",
      "Halkidi                   3\n",
      "Halkidi-Filtered Noise    3\n",
      "Halkidi-Bounded Noise     3\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clusters</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Silhouette</th>\n",
       "      <th>Halkidi</th>\n",
       "      <th>Halkidi-Filtered Noise</th>\n",
       "      <th>Halkidi-Bounded Noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2.852515e-01</td>\n",
       "      <td>1.016481e+00</td>\n",
       "      <td>5.598180e-01</td>\n",
       "      <td>5.261967e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Clusters     Noise    Silhouette       Halkidi  Halkidi-Filtered Noise  \\\n",
       "3          2  0.066667  2.852515e-01  1.016481e+00            5.598180e-01   \n",
       "4          0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "5          0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "6          0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "7          0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "8          0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "9          0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "10         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "11         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "12         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "13         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "14         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "15         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "16         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "17         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "18         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "19         0  1.000000  2.147484e+09  2.147484e+09            2.147484e+09   \n",
       "\n",
       "    Halkidi-Bounded Noise  \n",
       "3            5.261967e-01  \n",
       "4            2.147484e+09  \n",
       "5            2.147484e+09  \n",
       "6            2.147484e+09  \n",
       "7            2.147484e+09  \n",
       "8            2.147484e+09  \n",
       "9            2.147484e+09  \n",
       "10           2.147484e+09  \n",
       "11           2.147484e+09  \n",
       "12           2.147484e+09  \n",
       "13           2.147484e+09  \n",
       "14           2.147484e+09  \n",
       "15           2.147484e+09  \n",
       "16           2.147484e+09  \n",
       "17           2.147484e+09  \n",
       "18           2.147484e+09  \n",
       "19           2.147484e+09  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_cluster_sizes=range(3,20,1)\n",
    "pipeline.train_clusterer(class_label=0, min_cluster_sizes=min_cluster_sizes, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    11\n",
       " 0     3\n",
       "-1     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pipeline.clusterer.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LRP Analyzers...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "samples, cluster_labels = pipeline.get_validation_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(cluster_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.667(+/- 0.045)\n",
      "\tSubcluster 0\n",
      "Size: 564\n",
      "SVM Accuracy: 0.764(+/- 0.063)\n",
      "\tSubcluster 1\n",
      "Size: 140\n",
      "SVM Accuracy: 1.000(+/- 0.000)\n",
      "\tSubcluster 2\n",
      "Size: 402\n",
      "SVM Accuracy: 0.843(+/- 0.096)\n",
      "\tSubcluster 3\n",
      "Size: 240\n",
      "SVM Accuracy: 0.842(+/- 0.122)\n",
      "----------------------\n",
      "Weighted Mean: 0.8260\n"
     ]
    }
   ],
   "source": [
    "#### if __name__ == \"__main__\":\n",
    "#     from sklearn.svm import LinearSVC\n",
    "#     from sklearn.model_selection import GridSearchCV\n",
    "#     from sklearn.model_selection import cross_val_score\n",
    "#     from sklearn.pipeline import Pipeline\n",
    "#     from sklearn.preprocessing import StandardScaler\n",
    "#     import numpy as np\n",
    "\n",
    "\n",
    "#     original_val_samples = pipeline.val_set.features[pipeline.val_pred_mask]\n",
    "#     original_val_labels = pipeline.val_set.labels[pipeline.val_pred_mask]\n",
    "\n",
    "#     svm_clf = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"SVM\", LinearSVC(**{'C': 10, 'loss': 'hinge', 'max_iter': 10000000, 'tol': 0.0001}))\n",
    "#     ])\n",
    "#     _score = cross_val_score(svm_clf, X = original_val_samples, y=original_val_labels, cv=10)\n",
    "#     print(\"SVM Accuracy: {:0.3f}(+/- {:.3f})\".format(_score.mean(), _score.std()*2))\n",
    "    \n",
    "#     center_class = original_val_samples[original_val_labels == 1]\n",
    "#     target_class = original_val_samples[original_val_labels == 0]\n",
    "#     center_labels = [-1]* len(original_val_labels[original_val_labels == 1])\n",
    "\n",
    "#     # Separate training set for each class with\n",
    "#     # equal amounts of subcluster and center blob\n",
    "#     xtrain = {}\n",
    "#     start = 0\n",
    "#     for i in range(0,cluster_labels.max()+1):\n",
    "        \n",
    "#         _subclass = target_class[cluster_labels == i]\n",
    "#         _labels = cluster_labels[ cluster_labels == i]\n",
    "        \n",
    "#         end = start+len(_subclass)\n",
    "#         _xtrain = np.concatenate((center_class[start:end], _subclass))\n",
    "#         _ytrain = np.concatenate((center_labels[start:end], _labels))\n",
    "        \n",
    "#         xtrain[i] = (_xtrain, _ytrain)\n",
    "#         start += len(_subclass)\n",
    "#     # print(xtrain)\n",
    "#     scores = []\n",
    "#     sizes = [len(xtrain[i][1]) for i in xtrain]\n",
    "\n",
    "#     for i in xtrain:\n",
    "#         print(\"\\tSubcluster\",i)\n",
    "#         print(\"Size:\", sizes[i] )\n",
    "        \n",
    "#         _score = cross_val_score(svm_clf, X = xtrain[i][0], y=xtrain[i][1], cv=10)\n",
    "        \n",
    "#     #     %time svm_clf.fit(_xtrain, _ytrain)\n",
    "#         scores.append(_score)\n",
    "#         print(\"SVM Accuracy: {:0.3f}(+/- {:.3f})\".format(_score.mean(), _score.std()*2))\n",
    "        \n",
    "#     print(\"----------------------\")\n",
    "#     # subcluster_avg = np.mean([s.mean() for s in scores])\n",
    "#     # print(\"Mean Score: {:0.4f}\".format(subcluster_avg))\n",
    "\n",
    "#     # This is actually the \"true\" mean: sum(correctly classified) / (total samples)\n",
    "#     weighted_avg = sum([sz*sc.mean() for sz,sc in zip(sizes,scores)])/sum(sizes)\n",
    "#     print(\"Weighted Mean: {:0.4f}\".format(weighted_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python (condatensor)",
   "language": "python",
   "name": "condatensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
