{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"/Users/Work/Developer/interpretDL/interprettensor\")\n",
    "root_logdir = \"./tf_logs\"\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    \n",
    "def remove_label(features, labels, label=\"MCI\"):\n",
    "    labels = pd.Series(fused_labels)\n",
    "    non_samples = labels != label\n",
    "\n",
    "    stripped_features = features[non_samples]\n",
    "    stripped_labels = labels[non_samples]\n",
    "\n",
    "    return stripped_features, stripped_labels\n",
    "\n",
    "def get_split(features, labels):\n",
    "    features = np.array(features)\n",
    "    # The train set will have equal amounts of each target class\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(features, labels):\n",
    "        X_train = features[train_index]\n",
    "        y_train = labels[train_index]\n",
    "        X_test = features[test_index]\n",
    "        y_test = labels[test_index]\n",
    "        \n",
    "        yield X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Helper Functions\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "######### Taken from sklearn #######\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=[8,8])\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "class AttributeRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Returns a copy of matrix with attributes removed\n",
    "    \"\"\"\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return # Doesn't do anything\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop(columns=self.attribute_names)\n",
    "\n",
    "# class OverSampler(BaseEstimator, TransformerMixin):\n",
    "#     \"\"\"\n",
    "#     Returns a copy of matrix with attributes removed\n",
    "#     \"\"\"\n",
    "#     def __init__(self, random_state=42):\n",
    "#         self.smote = SMOTE(random_state=random_state)\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         self.smote.fit(X,y)\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X, y=None):\n",
    "#         return self.smote.resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting MNIST data\n",
    "# (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# # Converting to float and normalizing\n",
    "# X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "# X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "# y_train = y_train.astype(np.int32)\n",
    "# y_test = y_test.astype(np.int32)\n",
    "\n",
    "# # Separating out validation set\n",
    "# X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "# y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "# X_train.shape\n",
    "\n",
    "# svm_clf = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"SVM\", SVC(kernel= \"rbf\", gamma= 10, C=0.01))\n",
    "# ])\n",
    "\n",
    "# %time svm_clf.fit(X_train[:500], y_train[:500])\n",
    "# svm_clf.score(X_valid[:100], y_valid[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on ADNI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143 entries, 0 to 142\n",
      "Columns: 300 entries, PTID to DX_bl\n",
      "dtypes: float64(149), int64(148), object(3)\n",
      "memory usage: 335.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G_and_S_frontomargin_TH_lh</th>\n",
       "      <th>G_and_S_occipital_inf_TH_lh</th>\n",
       "      <th>G_and_S_paracentral_TH_lh</th>\n",
       "      <th>G_and_S_subcentral_TH_lh</th>\n",
       "      <th>G_and_S_transv_frontopol_TH_lh</th>\n",
       "      <th>G_and_S_cingul-Ant_TH_lh</th>\n",
       "      <th>G_and_S_cingul-Mid-Ant_TH_lh</th>\n",
       "      <th>G_and_S_cingul-Mid-Post_TH_lh</th>\n",
       "      <th>G_cingul-Post-dorsal_TH_lh</th>\n",
       "      <th>G_cingul-Post-ventral_TH_lh</th>\n",
       "      <th>...</th>\n",
       "      <th>S_parieto_occipital_TH_rh</th>\n",
       "      <th>S_pericallosal_TH_rh</th>\n",
       "      <th>S_postcentral_TH_rh</th>\n",
       "      <th>S_precentral-inf-part_TH_rh</th>\n",
       "      <th>S_precentral-sup-part_TH_rh</th>\n",
       "      <th>S_suborbital_TH_rh</th>\n",
       "      <th>S_subparietal_TH_rh</th>\n",
       "      <th>S_temporal_inf_TH_rh</th>\n",
       "      <th>S_temporal_sup_TH_rh</th>\n",
       "      <th>S_temporal_transverse_TH_rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.00000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.069462</td>\n",
       "      <td>2.243112</td>\n",
       "      <td>2.133825</td>\n",
       "      <td>2.404769</td>\n",
       "      <td>2.355056</td>\n",
       "      <td>2.439280</td>\n",
       "      <td>2.423490</td>\n",
       "      <td>2.331692</td>\n",
       "      <td>2.768000</td>\n",
       "      <td>2.113336</td>\n",
       "      <td>...</td>\n",
       "      <td>1.908979</td>\n",
       "      <td>2.435364</td>\n",
       "      <td>1.818832</td>\n",
       "      <td>2.152860</td>\n",
       "      <td>2.061657</td>\n",
       "      <td>2.278923</td>\n",
       "      <td>2.054643</td>\n",
       "      <td>2.156196</td>\n",
       "      <td>2.13651</td>\n",
       "      <td>1.970483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.189288</td>\n",
       "      <td>0.225751</td>\n",
       "      <td>0.192844</td>\n",
       "      <td>0.182563</td>\n",
       "      <td>0.210286</td>\n",
       "      <td>0.203912</td>\n",
       "      <td>0.205958</td>\n",
       "      <td>0.156330</td>\n",
       "      <td>0.231382</td>\n",
       "      <td>0.287778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151877</td>\n",
       "      <td>0.302305</td>\n",
       "      <td>0.145345</td>\n",
       "      <td>0.155362</td>\n",
       "      <td>0.169625</td>\n",
       "      <td>0.499660</td>\n",
       "      <td>0.199281</td>\n",
       "      <td>0.255395</td>\n",
       "      <td>0.14085</td>\n",
       "      <td>0.325659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.617000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>1.598000</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>1.785000</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>1.868000</td>\n",
       "      <td>1.914000</td>\n",
       "      <td>1.792000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343000</td>\n",
       "      <td>1.613000</td>\n",
       "      <td>1.422000</td>\n",
       "      <td>1.622000</td>\n",
       "      <td>1.464000</td>\n",
       "      <td>1.421000</td>\n",
       "      <td>1.573000</td>\n",
       "      <td>1.573000</td>\n",
       "      <td>1.73700</td>\n",
       "      <td>1.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.942000</td>\n",
       "      <td>2.079500</td>\n",
       "      <td>2.011000</td>\n",
       "      <td>2.284500</td>\n",
       "      <td>2.218500</td>\n",
       "      <td>2.311000</td>\n",
       "      <td>2.334000</td>\n",
       "      <td>2.229500</td>\n",
       "      <td>2.616500</td>\n",
       "      <td>1.923000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.809000</td>\n",
       "      <td>2.209500</td>\n",
       "      <td>1.718500</td>\n",
       "      <td>2.067500</td>\n",
       "      <td>1.941500</td>\n",
       "      <td>1.956000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>1.971500</td>\n",
       "      <td>2.02750</td>\n",
       "      <td>1.715500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.045000</td>\n",
       "      <td>2.239000</td>\n",
       "      <td>2.123000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>2.348000</td>\n",
       "      <td>2.432000</td>\n",
       "      <td>2.436000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>2.787000</td>\n",
       "      <td>2.094000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.899000</td>\n",
       "      <td>2.470000</td>\n",
       "      <td>1.813000</td>\n",
       "      <td>2.151000</td>\n",
       "      <td>2.074000</td>\n",
       "      <td>2.177000</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>2.129000</td>\n",
       "      <td>2.13800</td>\n",
       "      <td>1.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.162500</td>\n",
       "      <td>2.383000</td>\n",
       "      <td>2.275500</td>\n",
       "      <td>2.516500</td>\n",
       "      <td>2.495500</td>\n",
       "      <td>2.569000</td>\n",
       "      <td>2.556000</td>\n",
       "      <td>2.435000</td>\n",
       "      <td>2.912000</td>\n",
       "      <td>2.282000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.004500</td>\n",
       "      <td>2.623000</td>\n",
       "      <td>1.922000</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>2.158500</td>\n",
       "      <td>2.521000</td>\n",
       "      <td>2.168000</td>\n",
       "      <td>2.364000</td>\n",
       "      <td>2.23750</td>\n",
       "      <td>2.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.729000</td>\n",
       "      <td>2.872000</td>\n",
       "      <td>2.639000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.984000</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>2.972000</td>\n",
       "      <td>2.889000</td>\n",
       "      <td>3.447000</td>\n",
       "      <td>3.015000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.399000</td>\n",
       "      <td>3.274000</td>\n",
       "      <td>2.144000</td>\n",
       "      <td>2.683000</td>\n",
       "      <td>2.597000</td>\n",
       "      <td>4.421000</td>\n",
       "      <td>2.643000</td>\n",
       "      <td>2.808000</td>\n",
       "      <td>2.46100</td>\n",
       "      <td>3.042000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       G_and_S_frontomargin_TH_lh  G_and_S_occipital_inf_TH_lh  \\\n",
       "count                  143.000000                   143.000000   \n",
       "mean                     2.069462                     2.243112   \n",
       "std                      0.189288                     0.225751   \n",
       "min                      1.617000                     1.780000   \n",
       "25%                      1.942000                     2.079500   \n",
       "50%                      2.045000                     2.239000   \n",
       "75%                      2.162500                     2.383000   \n",
       "max                      2.729000                     2.872000   \n",
       "\n",
       "       G_and_S_paracentral_TH_lh  G_and_S_subcentral_TH_lh  \\\n",
       "count                 143.000000                143.000000   \n",
       "mean                    2.133825                  2.404769   \n",
       "std                     0.192844                  0.182563   \n",
       "min                     1.598000                  1.850000   \n",
       "25%                     2.011000                  2.284500   \n",
       "50%                     2.123000                  2.420000   \n",
       "75%                     2.275500                  2.516500   \n",
       "max                     2.639000                  2.800000   \n",
       "\n",
       "       G_and_S_transv_frontopol_TH_lh  G_and_S_cingul-Ant_TH_lh  \\\n",
       "count                      143.000000                143.000000   \n",
       "mean                         2.355056                  2.439280   \n",
       "std                          0.210286                  0.203912   \n",
       "min                          1.785000                  1.920000   \n",
       "25%                          2.218500                  2.311000   \n",
       "50%                          2.348000                  2.432000   \n",
       "75%                          2.495500                  2.569000   \n",
       "max                          2.984000                  3.010000   \n",
       "\n",
       "       G_and_S_cingul-Mid-Ant_TH_lh  G_and_S_cingul-Mid-Post_TH_lh  \\\n",
       "count                    143.000000                     143.000000   \n",
       "mean                       2.423490                       2.331692   \n",
       "std                        0.205958                       0.156330   \n",
       "min                        1.868000                       1.914000   \n",
       "25%                        2.334000                       2.229500   \n",
       "50%                        2.436000                       2.330000   \n",
       "75%                        2.556000                       2.435000   \n",
       "max                        2.972000                       2.889000   \n",
       "\n",
       "       G_cingul-Post-dorsal_TH_lh  G_cingul-Post-ventral_TH_lh  ...  \\\n",
       "count                  143.000000                   143.000000  ...   \n",
       "mean                     2.768000                     2.113336  ...   \n",
       "std                      0.231382                     0.287778  ...   \n",
       "min                      1.792000                     1.380000  ...   \n",
       "25%                      2.616500                     1.923000  ...   \n",
       "50%                      2.787000                     2.094000  ...   \n",
       "75%                      2.912000                     2.282000  ...   \n",
       "max                      3.447000                     3.015000  ...   \n",
       "\n",
       "       S_parieto_occipital_TH_rh  S_pericallosal_TH_rh  S_postcentral_TH_rh  \\\n",
       "count                 143.000000            143.000000           143.000000   \n",
       "mean                    1.908979              2.435364             1.818832   \n",
       "std                     0.151877              0.302305             0.145345   \n",
       "min                     1.343000              1.613000             1.422000   \n",
       "25%                     1.809000              2.209500             1.718500   \n",
       "50%                     1.899000              2.470000             1.813000   \n",
       "75%                     2.004500              2.623000             1.922000   \n",
       "max                     2.399000              3.274000             2.144000   \n",
       "\n",
       "       S_precentral-inf-part_TH_rh  S_precentral-sup-part_TH_rh  \\\n",
       "count                   143.000000                   143.000000   \n",
       "mean                      2.152860                     2.061657   \n",
       "std                       0.155362                     0.169625   \n",
       "min                       1.622000                     1.464000   \n",
       "25%                       2.067500                     1.941500   \n",
       "50%                       2.151000                     2.074000   \n",
       "75%                       2.245000                     2.158500   \n",
       "max                       2.683000                     2.597000   \n",
       "\n",
       "       S_suborbital_TH_rh  S_subparietal_TH_rh  S_temporal_inf_TH_rh  \\\n",
       "count          143.000000           143.000000            143.000000   \n",
       "mean             2.278923             2.054643              2.156196   \n",
       "std              0.499660             0.199281              0.255395   \n",
       "min              1.421000             1.573000              1.573000   \n",
       "25%              1.956000             1.910000              1.971500   \n",
       "50%              2.177000             2.056000              2.129000   \n",
       "75%              2.521000             2.168000              2.364000   \n",
       "max              4.421000             2.643000              2.808000   \n",
       "\n",
       "       S_temporal_sup_TH_rh  S_temporal_transverse_TH_rh  \n",
       "count             143.00000                   143.000000  \n",
       "mean                2.13651                     1.970483  \n",
       "std                 0.14085                     0.325659  \n",
       "min                 1.73700                     1.319000  \n",
       "25%                 2.02750                     1.715500  \n",
       "50%                 2.13800                     1.895000  \n",
       "75%                 2.23750                     2.209500  \n",
       "max                 2.46100                     3.042000  \n",
       "\n",
       "[8 rows x 148 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"ICV_ADNI.csv\"\n",
    "raw_data = pd.read_csv(filename)\n",
    "print(raw_data.info())\n",
    "\n",
    "\n",
    "label_col = \"DX_bl\"\n",
    "non_feature_cols = [\"PTID\", \"scandate\", \"ICV\",label_col]\n",
    "\n",
    "# Getting all the columns related to surface area\n",
    "thickness_features = [x for x in features.columns if \"SA\" in x ]\n",
    "\n",
    "raw_features = AttributeRemover(attribute_names= non_feature_cols + thickness_features).transform(raw_data)\n",
    "raw_labels = raw_data[label_col].copy()\n",
    "\n",
    "raw_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CN    0.657895\n",
       "AD    0.342105\n",
       "dtype: float64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Mapping to convert labels\n",
    "DROP_MCI = True # Whether to drop MCI samples or not\n",
    "fuse_maps = {\"SMC\": \"CN\", \"EMCI\":\"MCI\", \"LMCI\":\"MCI\"}\n",
    "\n",
    "# Lambda fucntion to be used with Map func\n",
    "fuse = lambda x: fuse_maps[x] if x in fuse_maps else x\n",
    "dist = lambda x: pd.Series(x).value_counts()/len(x)\n",
    "\n",
    "fused_labels = pd.Series(list(map(fuse, raw_labels)))\n",
    "pd.Series(raw_labels).value_counts()\n",
    "\n",
    "features, labels = remove_label(raw_features, fused_labels) if DROP_MCI else (raw_features, fused_labels)\n",
    "print(\"Sample Size:\", len(labels))\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels_enc = le.fit_transform(labels)\n",
    "\n",
    "\n",
    "dist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: (60, 148)\n",
      "Test Size: (16,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get split returns a generator\n",
    "# List comprehension is one way to evaluate a generator\n",
    "X_train, y_train, X_test, y_test = list(get_split(features, labels_enc))[0]\n",
    "print(\"Train Size:\", X_train.shape)\n",
    "print(\"Test Size:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"SVM\", SVC(kernel= \"rbf\", gamma= \"scale\", C=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 ms, sys: 744 µs, total: 4.15 ms\n",
      "Wall time: 3.44 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('SVM', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "%time svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['AD' 'CN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Categories:\", le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[5 0]\n",
      " [2 9]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9174669aa324d2c993198377900859c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x130b92438>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, classes=le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on test set: accuracy=0.8750\n",
      "Scores on test set: accuracy=0.7500\n",
      "Scores on test set: accuracy=0.7500\n",
      "Scores on test set: accuracy=0.7500\n",
      "Scores on test set: accuracy=0.6250\n",
      "Scores on test set: accuracy=0.7500\n",
      "Scores on test set: accuracy=0.5714\n",
      "Scores on test set: accuracy=1.0000\n",
      "Scores on test set: accuracy=0.8571\n",
      "Scores on test set: accuracy=0.7143\n",
      "Average: 0.764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold as KFold\n",
    "\n",
    "def getKF(X,y, n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42 ) #Default = 10\n",
    "\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        yield X_train, y_train, X_test, y_test, test_index\n",
    "\n",
    "scores = 0\n",
    "testing_indxs =[]\n",
    "predictions = []\n",
    "true_labels = []\n",
    "zoo = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test, test_index in getKF(features, labels_enc):\n",
    "    \n",
    "    X,y = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    svm_clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"SVM\", SVC(kernel= \"rbf\", gamma= \"scale\", C=1))])\n",
    "    \n",
    "    \n",
    "    svm_clf.fit(X, y)\n",
    "    \n",
    "    acc = svm_clf.score(X_test, y_test)\n",
    "    scores += acc\n",
    "    \n",
    "    # Updating all information arrays\n",
    "    testing_indxs.append(test_index)\n",
    "#     zoo.append(dnn)\n",
    "    \n",
    "    y_true = y_test\n",
    "    y_pred = svm_clf.predict(X_test)\n",
    "    \n",
    "    predictions.extend(y_pred)\n",
    "    true_labels.extend(y_true)\n",
    "    \n",
    "    print(\"Scores on test set: accuracy={:.4f}\".format(acc))\n",
    "print(\"Average: {:.3f}\".format(scores/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[16  8]\n",
      " [10 42]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cb22bbac1f4177abfc3714fb92ef25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13085db70>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_confusion_matrix(predictions, true_labels, classes=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.66666667 0.33333333]\n",
      " [0.19230769 0.80769231]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d58728e983b48a2aebf34a728a9e91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1308695c0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_confusion_matrix(predictions, true_labels, classes=le.classes_, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaflow",
   "language": "python",
   "name": "condaflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
