{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half the data will be split out as validation and 0.2 as the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_split_index(features, labels, test_size=0.1):\n",
    "    features = np.array(features)\n",
    "    # The train set will have equal amounts of each target class\n",
    "    # Performing single split\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "    return [[train_index, test_index] for train_index,test_index in split.split(features, labels)]\n",
    "\n",
    "def split_valid(features, original_labels, training_labels):\n",
    "    train_index, validation_index = get_split_index(features, original_labels, test_size=0.5)[0]\n",
    "    \n",
    "    X_valid, y_valid, y_valid_original = features.iloc[validation_index],  training_labels.iloc[validation_index], original_labels.iloc[validation_index]\n",
    "    X_train, y_train, y_original = features.iloc[train_index], training_labels.iloc[train_index], original_labels.iloc[train_index]\n",
    "     \n",
    "    return X_train, y_train, y_original, X_valid, y_valid, y_valid_original\n",
    "\n",
    "def get_train_test_val(features, original_labels, training_labels):\n",
    "    \n",
    "    X, y, y_original, X_valid, y_valid, y_valid_original = split_valid(features,original_labels, training_labels)\n",
    "   \n",
    "    train_index, test_index = get_split_index(X, y_original)[0]\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, y_original, X_valid, y_valid, y_valid_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a DNN on the modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e19c34b8df34150979164b432f2005d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: (5400, 2)\n",
      "Test Size: (600,)\n",
      "Categories: [array([0, 1])]\n"
     ]
    }
   ],
   "source": [
    "# Get split returns a generator\n",
    "# List comprehension is one way to evaluate a generator\n",
    "\n",
    "original_data, modded_samples, training_labels, original_labels = simulate_blobs(class_size=6000)\n",
    "\n",
    "# Separating a hold out set that will be used for validation later\n",
    "X_train, y_train, X_test, y_test, y_original, X_valid, y_valid, y_valid_original = get_train_test_val(modded_samples, original_labels, training_labels)\n",
    "\n",
    "\n",
    "print(\"Train Size:\", X_train.shape)\n",
    "print(\"Test Size:\", y_test.shape)\n",
    "\n",
    "\n",
    "hot_encoder = dfHotEncoder()\n",
    "hot_encoder.fit(training_labels)\n",
    "print(\"Categories:\", hot_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = X_train.shape[1]\n",
    "NUM_LABELS = len(hot_encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn(num_features, num_labels=3):\n",
    "\n",
    "#     reset_graph()\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    nn = keras.models.Sequential()\n",
    "    Dense = keras.layers.Dense\n",
    "    \n",
    "    # Using He initialization\n",
    "    he_init = tf.keras.initializers.he_uniform()\n",
    "    \n",
    "    nn.add(Dense(units = 16, activation=\"relu\", input_dim=num_features,\n",
    "                kernel_initializer=he_init))\n",
    "    nn.add(Dense(units = 16, activation=\"relu\",\n",
    "                kernel_initializer=he_init))\n",
    "    nn.add(Dense(units = 16, activation=\"relu\",\n",
    "                kernel_initializer=he_init))\n",
    "    nn.add(Dense(units = 16, activation=\"relu\",\n",
    "            kernel_initializer=he_init))\n",
    "    nn.add(Dense(units=2, activation= \"softmax\",\n",
    "                kernel_initializer=he_init))\n",
    "\n",
    "#     BCE = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    \n",
    "    nn.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return nn\n",
    "\n",
    "def train_model(model, X, y, X_test=[], y_test=[], epochs=30, batch_size=20, verbose=1, plot=True):\n",
    "    \n",
    "    ZScaler = StandardScaler().fit(X)\n",
    "    \n",
    "    X_train = ZScaler.transform(X)\n",
    "    X_test = ZScaler.transform(X_test)\n",
    "    \n",
    "    y_train = hot_encoder.transform(y)\n",
    "    y_test = hot_encoder.transform(y_test)\n",
    "    \n",
    "#     lr_scheduler = keras.callbacks.LearningRateScheduler(exp_decay)\n",
    "    callback_list = []\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size = batch_size,\n",
    "                        validation_data=(X_test, y_test), callbacks=callback_list, verbose=verbose)\n",
    "    \n",
    "#     if plot: plot_history(history)\n",
    "    \n",
    "    return history, ZScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "5400/5400 [==============================] - 1s 141us/step - loss: 0.2032 - acc: 0.9381 - val_loss: 0.0392 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "5400/5400 [==============================] - 1s 126us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "5400/5400 [==============================] - 1s 99us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "5400/5400 [==============================] - 1s 100us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "5400/5400 [==============================] - 1s 109us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "5400/5400 [==============================] - 0s 90us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "5400/5400 [==============================] - 1s 96us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "5400/5400 [==============================] - 1s 93us/step - loss: 9.1866e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 7.8498e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "5400/5400 [==============================] - 1s 107us/step - loss: 6.8280e-04 - acc: 1.0000 - val_loss: 9.3990e-04 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 6.0256e-04 - acc: 1.0000 - val_loss: 8.6190e-04 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "5400/5400 [==============================] - 1s 101us/step - loss: 5.3785e-04 - acc: 1.0000 - val_loss: 7.9612e-04 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "5400/5400 [==============================] - 1s 100us/step - loss: 4.8481e-04 - acc: 1.0000 - val_loss: 7.4296e-04 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "5400/5400 [==============================] - 1s 100us/step - loss: 4.4069e-04 - acc: 1.0000 - val_loss: 6.9565e-04 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "5400/5400 [==============================] - 1s 106us/step - loss: 4.0329e-04 - acc: 1.0000 - val_loss: 6.5164e-04 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "5400/5400 [==============================] - 1s 104us/step - loss: 3.7156e-04 - acc: 1.0000 - val_loss: 6.1857e-04 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "5400/5400 [==============================] - 1s 106us/step - loss: 3.4410e-04 - acc: 1.0000 - val_loss: 5.8591e-04 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "5400/5400 [==============================] - 1s 95us/step - loss: 3.2027e-04 - acc: 1.0000 - val_loss: 5.6131e-04 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "5400/5400 [==============================] - 1s 95us/step - loss: 2.9928e-04 - acc: 1.0000 - val_loss: 5.3673e-04 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "5400/5400 [==============================] - 1s 100us/step - loss: 2.8072e-04 - acc: 1.0000 - val_loss: 5.1538e-04 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "5400/5400 [==============================] - 1s 106us/step - loss: 2.6414e-04 - acc: 1.0000 - val_loss: 4.9736e-04 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "5400/5400 [==============================] - 1s 106us/step - loss: 2.4931e-04 - acc: 1.0000 - val_loss: 4.7861e-04 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "5400/5400 [==============================] - 1s 101us/step - loss: 2.3593e-04 - acc: 1.0000 - val_loss: 4.6142e-04 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "5400/5400 [==============================] - 1s 99us/step - loss: 2.2382e-04 - acc: 1.0000 - val_loss: 4.4615e-04 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "5400/5400 [==============================] - 1s 104us/step - loss: 2.1280e-04 - acc: 1.0000 - val_loss: 4.2945e-04 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "5400/5400 [==============================] - 1s 99us/step - loss: 2.0273e-04 - acc: 1.0000 - val_loss: 4.1587e-04 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "5400/5400 [==============================] - 1s 102us/step - loss: 1.9346e-04 - acc: 1.0000 - val_loss: 4.0206e-04 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "5400/5400 [==============================] - 1s 107us/step - loss: 1.8501e-04 - acc: 1.0000 - val_loss: 3.9020e-04 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "5400/5400 [==============================] - 1s 94us/step - loss: 1.7720e-04 - acc: 1.0000 - val_loss: 3.7989e-04 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "5400/5400 [==============================] - 1s 106us/step - loss: 1.7001e-04 - acc: 1.0000 - val_loss: 3.6921e-04 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "5400/5400 [==============================] - 1s 112us/step - loss: 1.6334e-04 - acc: 1.0000 - val_loss: 3.5985e-04 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "5400/5400 [==============================] - 1s 103us/step - loss: 1.5713e-04 - acc: 1.0000 - val_loss: 3.4995e-04 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "5400/5400 [==============================] - 1s 98us/step - loss: 1.5137e-04 - acc: 1.0000 - val_loss: 3.4145e-04 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "5400/5400 [==============================] - 1s 102us/step - loss: 1.4602e-04 - acc: 1.0000 - val_loss: 3.3401e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "5400/5400 [==============================] - 1s 94us/step - loss: 1.4098e-04 - acc: 1.0000 - val_loss: 3.2757e-04 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "5400/5400 [==============================] - 1s 103us/step - loss: 1.3631e-04 - acc: 1.0000 - val_loss: 3.2110e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "5400/5400 [==============================] - 1s 109us/step - loss: 1.3186e-04 - acc: 1.0000 - val_loss: 3.1381e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "5400/5400 [==============================] - 1s 113us/step - loss: 1.2776e-04 - acc: 1.0000 - val_loss: 3.0778e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "5400/5400 [==============================] - 1s 107us/step - loss: 1.2380e-04 - acc: 1.0000 - val_loss: 3.0161e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "5400/5400 [==============================] - 1s 108us/step - loss: 1.2009e-04 - acc: 1.0000 - val_loss: 2.9575e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "5400/5400 [==============================] - 1s 103us/step - loss: 1.1660e-04 - acc: 1.0000 - val_loss: 2.9069e-04 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "5400/5400 [==============================] - 1s 108us/step - loss: 1.1327e-04 - acc: 1.0000 - val_loss: 2.8575e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "5400/5400 [==============================] - 1s 97us/step - loss: 1.1013e-04 - acc: 1.0000 - val_loss: 2.8051e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 1.0714e-04 - acc: 1.0000 - val_loss: 2.7625e-04 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 1.0432e-04 - acc: 1.0000 - val_loss: 2.7150e-04 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "5400/5400 [==============================] - 1s 98us/step - loss: 1.0161e-04 - acc: 1.0000 - val_loss: 2.6734e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "5400/5400 [==============================] - 0s 85us/step - loss: 9.9075e-05 - acc: 1.0000 - val_loss: 2.6323e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "5400/5400 [==============================] - 0s 86us/step - loss: 9.6609e-05 - acc: 1.0000 - val_loss: 2.5913e-04 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "5400/5400 [==============================] - 0s 84us/step - loss: 9.4268e-05 - acc: 1.0000 - val_loss: 2.5508e-04 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "5400/5400 [==============================] - 0s 92us/step - loss: 9.2038e-05 - acc: 1.0000 - val_loss: 2.5107e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "5400/5400 [==============================] - 0s 89us/step - loss: 8.9901e-05 - acc: 1.0000 - val_loss: 2.4749e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "5400/5400 [==============================] - 0s 89us/step - loss: 8.7857e-05 - acc: 1.0000 - val_loss: 2.4400e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "5400/5400 [==============================] - 1s 100us/step - loss: 8.5897e-05 - acc: 1.0000 - val_loss: 2.4062e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "5400/5400 [==============================] - 1s 99us/step - loss: 8.4018e-05 - acc: 1.0000 - val_loss: 2.3722e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "5400/5400 [==============================] - 1s 93us/step - loss: 8.2216e-05 - acc: 1.0000 - val_loss: 2.3403e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "5400/5400 [==============================] - 1s 104us/step - loss: 8.0482e-05 - acc: 1.0000 - val_loss: 2.3071e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "5400/5400 [==============================] - 1s 97us/step - loss: 7.8821e-05 - acc: 1.0000 - val_loss: 2.2786e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "5400/5400 [==============================] - 1s 97us/step - loss: 7.7216e-05 - acc: 1.0000 - val_loss: 2.2475e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "5400/5400 [==============================] - 1s 100us/step - loss: 7.5679e-05 - acc: 1.0000 - val_loss: 2.2217e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 7.4197e-05 - acc: 1.0000 - val_loss: 2.1942e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "5400/5400 [==============================] - 1s 103us/step - loss: 7.2768e-05 - acc: 1.0000 - val_loss: 2.1706e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "5400/5400 [==============================] - 1s 103us/step - loss: 7.1387e-05 - acc: 1.0000 - val_loss: 2.1475e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "5400/5400 [==============================] - 1s 100us/step - loss: 7.0055e-05 - acc: 1.0000 - val_loss: 2.1248e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "5400/5400 [==============================] - 1s 104us/step - loss: 6.8771e-05 - acc: 1.0000 - val_loss: 2.1029e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "5400/5400 [==============================] - 1s 97us/step - loss: 6.7532e-05 - acc: 1.0000 - val_loss: 2.0793e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "5400/5400 [==============================] - 0s 82us/step - loss: 6.6332e-05 - acc: 1.0000 - val_loss: 2.0564e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "5400/5400 [==============================] - 0s 76us/step - loss: 6.5170e-05 - acc: 1.0000 - val_loss: 2.0327e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "5400/5400 [==============================] - 0s 79us/step - loss: 6.4048e-05 - acc: 1.0000 - val_loss: 2.0130e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "5400/5400 [==============================] - 0s 82us/step - loss: 6.2963e-05 - acc: 1.0000 - val_loss: 1.9925e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 6.1909e-05 - acc: 1.0000 - val_loss: 1.9718e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "5400/5400 [==============================] - 0s 75us/step - loss: 6.0889e-05 - acc: 1.0000 - val_loss: 1.9532e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "5400/5400 [==============================] - 0s 77us/step - loss: 5.9899e-05 - acc: 1.0000 - val_loss: 1.9327e-04 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "5400/5400 [==============================] - 0s 81us/step - loss: 5.8941e-05 - acc: 1.0000 - val_loss: 1.9148e-04 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 5.8009e-05 - acc: 1.0000 - val_loss: 1.8973e-04 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "5400/5400 [==============================] - 0s 72us/step - loss: 5.7100e-05 - acc: 1.0000 - val_loss: 1.8803e-04 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "5400/5400 [==============================] - 0s 75us/step - loss: 5.6234e-05 - acc: 1.0000 - val_loss: 1.8616e-04 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "5400/5400 [==============================] - 0s 79us/step - loss: 5.5383e-05 - acc: 1.0000 - val_loss: 1.8433e-04 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "5400/5400 [==============================] - 0s 80us/step - loss: 5.4558e-05 - acc: 1.0000 - val_loss: 1.8259e-04 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "5400/5400 [==============================] - 0s 74us/step - loss: 5.3754e-05 - acc: 1.0000 - val_loss: 1.8106e-04 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 5.2974e-05 - acc: 1.0000 - val_loss: 1.7942e-04 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 5.2212e-05 - acc: 1.0000 - val_loss: 1.7774e-04 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 5.1473e-05 - acc: 1.0000 - val_loss: 1.7620e-04 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "5400/5400 [==============================] - 0s 87us/step - loss: 5.0753e-05 - acc: 1.0000 - val_loss: 1.7471e-04 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "5400/5400 [==============================] - 0s 86us/step - loss: 5.0049e-05 - acc: 1.0000 - val_loss: 1.7340e-04 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 4.9365e-05 - acc: 1.0000 - val_loss: 1.7207e-04 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "5400/5400 [==============================] - 0s 83us/step - loss: 4.8700e-05 - acc: 1.0000 - val_loss: 1.7067e-04 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "5400/5400 [==============================] - 0s 76us/step - loss: 4.8050e-05 - acc: 1.0000 - val_loss: 1.6934e-04 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 4.7415e-05 - acc: 1.0000 - val_loss: 1.6795e-04 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 4.6797e-05 - acc: 1.0000 - val_loss: 1.6668e-04 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 4.6194e-05 - acc: 1.0000 - val_loss: 1.6528e-04 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 4.5607e-05 - acc: 1.0000 - val_loss: 1.6397e-04 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 4.5028e-05 - acc: 1.0000 - val_loss: 1.6272e-04 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 4.4471e-05 - acc: 1.0000 - val_loss: 1.6149e-04 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 4.3921e-05 - acc: 1.0000 - val_loss: 1.6018e-04 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 4.3388e-05 - acc: 1.0000 - val_loss: 1.5892e-04 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 4.2866e-05 - acc: 1.0000 - val_loss: 1.5772e-04 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 4.2357e-05 - acc: 1.0000 - val_loss: 1.5662e-04 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "5400/5400 [==============================] - 0s 85us/step - loss: 4.1858e-05 - acc: 1.0000 - val_loss: 1.5558e-04 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "5400/5400 [==============================] - 0s 75us/step - loss: 4.1370e-05 - acc: 1.0000 - val_loss: 1.5451e-04 - val_acc: 1.0000\n",
      "CPU times: user 1min 16s, sys: 20.9 s, total: 1min 37s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "nn = build_dnn(NUM_FEATURES)\n",
    "%time history, Zscaler = train_model(nn, X_train, y_train, X_test, y_test, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e09fd07cbe4d82b285959551af2d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting results from history\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([6.1887513e-05, 9.9993813e-01], dtype=float32),\n",
       "  array([1.0000000e+00, 4.1414715e-11], dtype=float32),\n",
       "  array([2.8176837e-05, 9.9997187e-01], dtype=float32),\n",
       "  array([9.9999976e-01, 2.5156234e-07], dtype=float32),\n",
       "  array([1.0000000e+00, 1.4327063e-16], dtype=float32)],\n",
       " [1.0, 0.0, 1.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [x for x in nn.predict(Zscaler.transform(X_test[:5]))]\n",
    "_labels = [np.float(x) for x in y_test]\n",
    "preds[:5],_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing SVM on Modded Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.09 ms, sys: 1.45 ms, total: 8.54 ms\n",
      "Wall time: 7.2 ms\n",
      "Linear SVM Test Accuracy: 0.687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"SVM\", LinearSVC(C=1, loss=\"hinge\", max_iter=1000 ))\n",
    "])\n",
    "\n",
    "%time svm_clf.fit(X_train, y_train)\n",
    "print(\"Linear SVM Test Accuracy: {:0.3f}\".format(svm_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy\n",
      "6000/6000 [==============================] - 0s 12us/step\n",
      "Scores on validation set: loss=0.000 accuracy=1.0000\n"
     ]
    }
   ],
   "source": [
    "model = nn\n",
    "scaled_samples = Zscaler.transform(X_valid)\n",
    "_labels = y_valid\n",
    "# mod_labels = modded_labels[test_index]\n",
    "\n",
    "predictions = model.predict(scaled_samples)\n",
    "preds = np.array([np.argmax(x) for x in predictions])\n",
    "true_labels = np.array([x for x in _labels])\n",
    "\n",
    "correct = preds == true_labels\n",
    "# versicolor = true_labels == 1\n",
    "\n",
    "print(\"Validation Accuracy\")\n",
    "loss_and_metrics = model.evaluate(scaled_samples, hot_encoder.transform(y_valid))\n",
    "print(\"Scores on validation set: loss={:0.3f} accuracy={:.4f}\".format(*loss_and_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3000\n",
       "0    3000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_labels[correct].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "\n",
    "def perform_analysis(model, analyzer, data, labels=[]):\n",
    "    analysis = analyzer.analyze(data)\n",
    "    prediction = model.predict(data)\n",
    "    \n",
    "    df_anal = pd.DataFrame(analysis)\n",
    "    \n",
    "    return df_anal\n",
    "\n",
    "\n",
    "# Stripping the softmax activation from the model\n",
    "model_w_softmax = nn\n",
    "model = iutils.keras.graph.model_wo_softmax(model_w_softmax)\n",
    "\n",
    "# Creating an analyzer\n",
    "lrp_E = innvestigate.analyzer.relevance_based.relevance_analyzer.LRPEpsilon(model=model, epsilon=1e-3)\n",
    "lrp_Z = innvestigate.analyzer.relevance_based.relevance_analyzer.LRPZPlus(model=model)\n",
    "lrp_AB   = innvestigate.analyzer.relevance_based.relevance_analyzer.LRPAlpha2Beta1(model=model)\n",
    "\n",
    "# Getting all the samples that can be correctly predicted\n",
    "test_idx = correct\n",
    "all_samples = scaled_samples[test_idx]\n",
    "all_labels = y_valid_original[test_idx]\n",
    "\n",
    "\n",
    "# perform_analysis(nn,gradient_analyzer,flowers,types)\n",
    "all_lrp_AB = perform_analysis(model,lrp_AB, all_samples)\n",
    "all_lrp_E = perform_analysis(model,lrp_E, all_samples)\n",
    "all_lrp_Z = perform_analysis(model,lrp_Z, all_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c78805e482c4c8c987b351188f62700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"Comparison\")\n",
    "fig, axs = plt.subplots(2,2, figsize=(16,10), num=\"Comparison\")\n",
    "cmap = \"Set1\" #\"Paired\"\n",
    "plot_args = {\"kind\":\"scatter\", \"x\":0,  \"y\":1, \"c\":\"label\", \"cmap\": cmap, \"s\":10, \"alpha\":0.25}\n",
    "\n",
    "original_data.plot(ax=axs[0][0],title=\"Original Distribution\", **plot_args)\n",
    "\n",
    "plot_args[\"c\"] = all_labels\n",
    "all_lrp_E.plot(ax=axs[0][1], title=\"LRP E\", **plot_args)\n",
    "\n",
    "all_lrp_AB.plot(ax=axs[1][0], title=\"LRP AB\", **plot_args)\n",
    "all_lrp_Z.plot(ax=axs[1][1], title=\"LRP Z\", **plot_args)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(figures_dir+\"multiclass_lrp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# plt.show(block=False)\n",
    "# time.sleep(3)\n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db4af1e264d462e9dd1c4fcac68c907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"Positive Only LRP\")\n",
    "fig, axs = plt.subplots(1,3, figsize=(18,6), num=\"Positive Only LRP\")\n",
    "\n",
    "plot_args[\"c\"] = \"label\"\n",
    "original_data.plot(ax=axs[0], title=\"Original Distribution\", **plot_args)\n",
    "\n",
    "plot_args[\"c\"] = all_labels\n",
    "all_lrp_E.plot(ax=axs[1], title=\"LRP E\", **plot_args)\n",
    "\n",
    "pos_lrp = all_lrp_E.copy()\n",
    "pos_lrp[pos_lrp<0] = 0\n",
    "pos_lrp[\"label\"] = all_labels.values\n",
    "pos_lrp.plot(ax=axs[2],title=\"LRP E\", **plot_args)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.savefig(figures_dir+\"multiclass_noisy_lrp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128658e0065e46c3bde1e270e52dd009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotSeparatedLRP(pos_lrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaflow",
   "language": "python",
   "name": "condaflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
